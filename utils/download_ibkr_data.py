# ibkr_trading_bot/utils/download_ibkr_data.py
"""
Rolling stahovÃ¡nÃ­ historickÃ½ch dat z IBKR (napÅ™. GC futures) pomocÃ­ ib_insync.
SpustitelnÃ© pÅ™es main.py nebo samostatnÄ› s parametry.

NovÃ©: download_ibkr_by_date_range() - stahovÃ¡nÃ­ od data Do do teÄ po 5000 zÃ¡znamech
"""

import argparse
import os
import shutil
import tempfile
from datetime import datetime, timedelta
from pathlib import Path

import pandas as pd
from ib_insync import IB, Future, ContFuture, util


def download_ibkr_by_date_range(
    symbol: str,
    start_date: datetime,
    end_date: datetime | None = None,
    bar_size: str = "5 mins",
    contract_mode: str = "CONT",
    expiry: str | None = None,
    exchange: str | None = None,
    output_dir: str = "data/raw",
    max_bars_per_batch: int = 5000,
    host: str = "127.0.0.1",
    port: int = 7496,
    client_id: int = 1,
    on_progress=None,
) -> str:
    """
    Stahuje IBKR data od start_date do end_date (teÄ) po batchÃ­ch.
    
    Args:
        symbol: Ticker (napÅ™. 'GC')
        start_date: Od kdy stahovat (datetime)
        end_date: AÅ¾ kdy (default=nynÃ­). Stahuje se od start_date k end_date
        bar_size: Granularita ('5 mins', '1 hour', atd.)
        contract_mode: 'CONT' (kontinuÃ¡lnÃ­ futures) nebo 'FUT' (s expiracÃ­)
        expiry: Expirace (nutnÃ¡ pro FUT, napÅ™. '202602')
        output_dir: CÃ­lovÃ¡ sloÅ¾ka
        max_bars_per_batch: PoÄet barÅ¯ na batch (max 5000)
        host, port, client_id: TWS/Gateway para
        on_progress: Callback fn(batch_num, total_batches, records_downloaded)
    
    Returns:
        Cesta k finÃ¡lnÃ­mu slouÄenÃ©mu CSV souboru
    """
    if end_date is None:
        end_date = datetime.now()
    
    # Normalizace na naive (bez timezone) pro porovnÃ¡vÃ¡nÃ­
    if start_date.tzinfo is not None:
        start_date = start_date.replace(tzinfo=None)
    if end_date.tzinfo is not None:
        end_date = end_date.replace(tzinfo=None)
    
    os.makedirs(output_dir, exist_ok=True)
    
    # PÅ™ipojenÃ­
    ib = IB()
    ib.connect(host, port, clientId=client_id)
    
    try:
        # Definice kontraktu
        what_to_show = "TRADES"
        # Special mapping: GOLD on TVC -> use GC future with expiry 202602 (explicit FUT)
        if exchange is not None and str(exchange).upper() == "TVC" and str(symbol).upper() == "GOLD":
            # Map GOLD/TVC to COMEX gold future GC (example expiry 202602)
            expiry_used = expiry or "202602"
            contract = Future("GC", expiry_used, "COMEX", currency="USD")
            what_to_show = "TRADES"
        else:
            if contract_mode.upper() == "CONT":
                contract = ContFuture(symbol, "COMEX")
                what_to_show = "TRADES"
            else:  # FUT
                if not expiry:
                    raise ValueError("Expirace (--expiry) je povinnÃ¡ pro kontrakty FUT")
                contract = Future(symbol, expiry, "COMEX", currency="USD")
                what_to_show = "TRADES"
        
        ib.qualifyContracts(contract)

        # Pokud je to kontinuÃ¡lnÃ­ future, IB zakazuje nastavit endDateTime
        # proto pouÅ¾ijeme konkrÃ©tnÃ­ FUT kontrakt podle resolved expiry
        if isinstance(contract, ContFuture):
            expiry_resolved = getattr(contract, "lastTradeDateOrContractMonth", None) or expiry
            if not expiry_resolved:
                raise RuntimeError(
                    "KontinuÃ¡lnÃ­ futures nelze stÃ¡hnout s endDateTime; zadejte prosÃ­m expiraci (FUT mode) nebo pouÅ¾ijte jinÃ½ symbol."
                )
            contract = Future(
                contract.symbol,
                expiry_resolved,
                getattr(contract, "exchange", "COMEX"),
                currency=getattr(contract, "currency", "USD"),
            )
            ib.qualifyContracts(contract)

        # StahovÃ¡nÃ­ po batchÃ­ch
        all_batches = []
        batch_num = 0
        current_end = end_date
        
        temp_dir = Path(tempfile.gettempdir()) / f"ibkr_download_temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¥ StahovÃ¡nÃ­ {symbol} od {start_date.date()} do {end_date.date()}")
        print(f"   Mode: {contract_mode} | Bar: {bar_size} | Max: {max_bars_per_batch} barÅ¯/batch")
        
        while current_end > start_date:
            batch_num += 1
            end_str = current_end.strftime("%Y%m%d %H:%M:%S")
            
            # VypoÄti durationStr tak, aby pokryl pÅ™ibliÅ¾nÄ› max_bars_per_batch
            # napÅ™. pokud bar_size='5 mins' a max_bars_per_batch=5000 => 5000*5 minutes
            def _minutes_per_bar(bs: str) -> int:
                s = bs.strip().lower()
                if s.endswith('min') or s.endswith('mins'):
                    return int(s.split()[0]) if ' ' in s else int(s.replace('mins','').replace('min',''))
                if s.endswith('hour') or s.endswith('hours'):
                    return int(s.split()[0]) * 60
                if s.endswith('day') or s.endswith('days'):
                    return int(s.split()[0]) * 60 * 24
                # fallback assume minutes
                try:
                    return int(s)
                except Exception:
                    return 5

            minutes_per_bar = _minutes_per_bar(bar_size)
            total_minutes = max_bars_per_batch * max(1, minutes_per_bar)
            if total_minutes >= 60 * 24:
                days = max(1, (total_minutes + 60*24 - 1) // (60*24))
                durationStr = f"{days} D"
            elif total_minutes >= 60:
                hours = max(1, (total_minutes + 59) // 60)
                durationStr = f"{hours} H"
            else:
                durationStr = f"{max(1, total_minutes)} S"

            # StaÅ¾enÃ­ data
            bars = ib.reqHistoricalData(
                contract,
                endDateTime=end_str,
                durationStr=durationStr,
                barSizeSetting=bar_size,
                whatToShow=what_to_show,
                useRTH=False,
                formatDate=1,
                keepUpToDate=False,
            )
            
            if not bars:
                print(f"  âš ï¸  Batch {batch_num}: Å½Ã¡dnÃ¡ data, konec.")
                break
            
            df = util.df(bars)
            if df is None or df.empty:
                print(f"  âš ï¸  Batch {batch_num}: PrÃ¡zdnÃ¡ data, konec.")
                break
            
            # OkleÅ¡tÄ›nÃ­ na max_bars_per_batch pokud je vÃ­ce
            if len(df) > max_bars_per_batch:
                df = df.tail(max_bars_per_batch).copy()
            
            # FiltrovÃ¡nÃ­: vezmi jen zÃ¡znamy >= start_date
            df["date"] = pd.to_datetime(df["date"])
            # Normalizuj date na naive (bez timezone) pro porovnÃ¡nÃ­
            df["date"] = df["date"].dt.tz_localize(None)
            df = df[df["date"] >= start_date].copy()
            
            if df.empty:
                print(f"  âœ“ Batch {batch_num}: DosaÅ¾en zaÄÃ¡tek ({start_date.date()}), konec.")
                break
            
            # UloÅ¾enÃ­
            batch_path = temp_dir / f"batch_{batch_num:04d}.csv"
            df.to_csv(batch_path, index=False)
            all_batches.append(df)
            
            print(f"  âœ“ Batch {batch_num}: {len(df)} barÅ¯ (od {df['date'].min().date()})")
            
            if on_progress:
                on_progress(batch_num, None, len(df))
            
            # Posun back
            current_end = df["date"].min() - timedelta(minutes=1)
            
            # Pacing
            import time
            time.sleep(1.0)
        
        # Merge vÅ¡ech batchÃ­
        if not all_batches:
            raise RuntimeError("Å½Ã¡dnÃ¡ data se nestÃ¡hla!")
        
        print(f"\nğŸ”— SluÄuji {len(all_batches)} batchÅ¯...")
        df_merged = pd.concat(all_batches, ignore_index=True)
        df_merged["date"] = pd.to_datetime(df_merged["date"])
        # Normalizuj na naive (bez timezone)
        df_merged["date"] = df_merged["date"].dt.tz_localize(None)
        df_merged = df_merged.sort_values("date").drop_duplicates(subset=["date"])
        
        # FiltrovÃ¡nÃ­ pÅ™esnÄ› na rozsah
        df_merged = df_merged[(df_merged["date"] >= start_date) & (df_merged["date"] <= end_date)]
        
        # UloÅ¾enÃ­
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        bar_tag = bar_size.replace(" ", "").replace("mins", "m")
        fname = f"{symbol}_{bar_tag}_{len(df_merged)}bars_{start_date.strftime('%Y%m%d')}_{timestamp}.csv"
        output_path = Path(output_dir) / fname
        
        # FormÃ¡t: date,open,high,low,close,volume
        cols = ["date", "open", "high", "low", "close", "volume"]
        if "average" in df_merged.columns:
            cols.append("average")
        if "barCount" in df_merged.columns:
            cols.append("barCount")
        
        df_out = df_merged[cols].copy()
        df_out.to_csv(output_path, index=False)
        
        # ÄŒiÅ¡tÄ›nÃ­ temp dir
        import shutil
        shutil.rmtree(temp_dir, ignore_errors=True)
        
        print(f"\nâœ… Hotovo: {len(df_merged)} barÅ¯")
        print(f"   Rozsah: {df_merged['date'].min().date()} aÅ¾ {df_merged['date'].max().date()}")
        print(f"   Soubor: {output_path}")
        
        return str(output_path)
    
    finally:
        ib.disconnect()




def download_data(symbol: str, expiry: str, days_back: int, bar_size: str, output_dir: str = "data/raw"):
    # PÅ™ipojenÃ­ k IB Gateway
    ib = IB()
    ib.connect('127.0.0.1', 7496, clientId=1)

    # Definice kontraktu s expiracÃ­
    contract = Future(
        symbol=symbol,
        lastTradeDateOrContractMonth=expiry,
        exchange='COMEX',
        currency='USD'
    )

    os.makedirs(output_dir, exist_ok=True)
    all_data = []

    print(f"Stahuji data pro {symbol} ({expiry}) za poslednÃ­ch {days_back} dnÅ¯...")

    for i in range(days_back):
        day = datetime.now() - timedelta(days=i)
        day_str = day.strftime('%Y%m%d %H:%M:%S')
        print(f"  â¤ Den {i+1}: {day.date()}")

        bars = ib.reqHistoricalData(
            contract,
            endDateTime=day_str,
            durationStr='1 D',
            barSizeSetting=bar_size,
            whatToShow='TRADES',
            useRTH=False,
            formatDate=1
        )

        if not bars:
            print(f"    âš ï¸  Å½Ã¡dnÃ¡ data pro den {day.date()}")
            continue

        df = util.df(bars)
        df.drop_duplicates(subset='date', inplace=True)
        df.set_index('date', inplace=True)
        df.sort_index(inplace=True)

        # Kontrola ÄasovÃ½ch mezer
        df['delta'] = df.index.to_series().diff()
        if (df['delta'] > pd.Timedelta(minutes=5)).any():
            print("    âš ï¸  Mezery mezi svÃ­Äkami detekovÃ¡ny")
        df.drop(columns='delta', inplace=True)

        all_data.append(df)

    if all_data:
        df_all = pd.concat(all_data)
        df_all = df_all[~df_all.index.duplicated()]
        df_all.sort_index(inplace=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        bar_tag = bar_size.replace(' ', '')
        filename = f"{output_dir}/{symbol}_{expiry}_{bar_tag}_{days_back}d_{timestamp}.csv"
        df_all.to_csv(filename)

        shutil.copy2(filename, f"{output_dir}/ohlc_data.csv")
        print(f"ğŸ“„ ZkopÃ­rovÃ¡no takÃ© jako: {output_dir}/ohlc_data.csv")

        print(f"\nâœ… StaÅ¾eno {len(df_all)} svÃ­Äek")
        print(f"Rozsah: {df_all.index.min()} aÅ¾ {df_all.index.max()}")
        print(f"UloÅ¾eno do: {filename}")
    else:
        print("âŒ NepodaÅ™ilo se stÃ¡hnout Å¾Ã¡dnÃ¡ data.")

    ib.disconnect()


# VolitelnÄ›: samostatnÃ© spouÅ¡tÄ›nÃ­ pro test
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="StaÅ¾enÃ­ historickÃ½ch dat z IBKR.")
    parser.add_argument('--symbol', type=str, required=True, help='NapÅ™. GC')
    parser.add_argument('--expiry', type=str, required=True, help='NapÅ™. 202509')
    parser.add_argument('--days', type=int, default=30, help='PoÄet dnÅ¯ zpÄ›t')
    parser.add_argument('--barSize', type=str, default='5 mins', help='Granularita, napÅ™. "5 mins"')
    parser.add_argument('--output', type=str, default='data/raw', help='SloÅ¾ka pro CSV')

    args = parser.parse_args()

    download_data(
        symbol=args.symbol,
        expiry=args.expiry,
        days_back=args.days,
        bar_size=args.barSize,
        output_dir=args.output
    )
